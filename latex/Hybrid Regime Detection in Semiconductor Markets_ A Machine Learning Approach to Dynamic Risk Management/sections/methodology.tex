\section{Methodology}

\subsection{1. Data \& Features}
We construct our asset universe from major semiconductor equities and sector ETFs, including \texttt{SMH}, \texttt{SOXX}, \texttt{NVDA}, \texttt{AMD}, \texttt{TSM}, \texttt{INTC}, \texttt{QCOM}, and \texttt{AVGO}. The primary sample period spans from January 1, 2019 to January 1, 2024, with daily frequency, as detailed in our configuration and results summary.

Feature engineering is central to our approach. We extract a rich set of price-based features (returns, log-returns, realized and exponential volatility, momentum over multiple windows, rolling skewness and kurtosis), technical indicators (RSI, MACD, Bollinger position, Williams~\%R, on-balance volume), and sector-specific signals (semiconductor PMI proxy, memory vs. logic spread, equipment vs. design volatility ratio). Macro proxies such as VIX, yield spreads, and dollar strength are also included, either from external data or as rolling proxies.

Data cleaning involves forward-filling missing values, winsorizing extreme feature values (1st/99th percentiles), and standardizing all features using a robust or standard scaler. This ensures comparability and stability for downstream modeling.

\subsection{2. Regime Detection Models}
We employ a hybrid regime detection framework combining a Gaussian Hidden Markov Model (HMM) and a deep learning-based LSTM classifier. The HMM is initialized using KMeans clustering and fit to the engineered features, learning latent market regimes characterized by distinct volatility and return profiles. The number of regimes (typically 3--5) is a configurable hyperparameter.

The LSTM model is trained on the same features, using the HMM's regime assignments as initial labels. The LSTM architecture includes multiple (optionally bidirectional) layers, attention mechanisms, dropout, and batch normalization, enabling it to capture nonlinear and temporal dependencies in regime dynamics.

Regime assignments are smoothed using a rolling mode filter to reduce spurious switching. Confidence thresholds are applied to flag uncertain periods.

\subsection{3. Model Fusion / Ensemble}
To leverage the complementary strengths of HMM (interpretable, probabilistic) and LSTM (flexible, nonlinear), we fuse their outputs using Bayesian model averaging. Regime probabilities from both models are combined, with weights determined by recent predictive entropy or log-evidence. Entropy is computed over the regime probability vector at each timestep, and used to inversely weight low-confidence predictions during the fusion process. This ensemble approach improves robustness, especially during regime transitions or periods of model uncertainty.

Fusing models, rather than selecting a single approach, allows the system to adapt to changing market conditions and mitigates overfitting to any one modeling assumption.

\subsection{4. Trading Signal Generation}
Trading signals are generated using a momentum-based approach, combining short- and medium-term return sums, moving average crossovers, and price position relative to recent highs. Signals are clipped to the range $[-1, 1]$ and can be further normalized.

These continuous signals inform both directional positioning and sizing, depending on regime context---e.g., net long exposure during positive momentum in low-volatility regimes. Detected regimes influence signal interpretation and position sizing. For example, signals may be down-weighted or ignored in high-volatility regimes, or amplified in stable regimes. Signal quality is monitored via forward correlation with returns and basic diagnostics.

\subsection{5. Risk Management Strategy}
Risk is managed dynamically at both the signal and portfolio levels. Key metrics include Value-at-Risk (VaR), Expected Shortfall (ES), annualized volatility, Sharpe and Calmar ratios, and maximum drawdown. These are computed using historical, parametric, or Monte Carlo methods as appropriate.

Position sizing is adjusted based on regime confidence, recent volatility, and drawdown ratios. For example, in high-risk regimes or after large drawdowns, position sizes are automatically reduced. Stop-loss, take-profit, and maximum drawdown limits are enforced at the portfolio level.

\subsection{6. Backtesting Framework}
Model performance is evaluated using a modular backtesting engine. The framework supports configurable transaction costs, slippage, leverage, and rebalancing frequency (daily, monthly, etc.). Both single-period and walk-forward (rolling window) backtests are supported.

All model training and signal generation occur using past data only, ensuring no lookahead bias. Walk-forward analysis further validates generalizability across market regimes.

Performance metrics include total and annualized return, volatility, Sharpe and Calmar ratios, win rate, and turnover. Diagnostics such as position histories, trade counts, and confidence metrics are tracked for transparency.

\subsection{7. Scenario Analysis (Monte Carlo)}
To assess tail risk and model robustness, we simulate alternative return paths using bootstrap-based Monte Carlo methods. Thousands of synthetic return series are generated by resampling historical returns, and portfolio metrics (e.g., VaR, ES, drawdown) are computed across these scenarios. Optionally, regime-conditional or heavy-tailed (t-distribution) models can be substituted for bootstrap simulation to stress rare-event risk. This allows for quantification of uncertainty and stress-testing under extreme but plausible conditions.

\subsection{8. Overall System Design}
The entire framework is modular and extensible, with clear separation between data processing, feature engineering, regime detection, signal generation, risk management, and backtesting. Each component can be independently configured or replaced.

Components are connected end-to-end via standardized data structures (primarily pandas DataFrames), enabling seamless integration and reproducibility. The system is designed to support both batch (historical) and real-time operation, with hooks for live data updates and online regime detection.

% System pipeline flowchart (for formal submission, consider converting to a figure)
\paragraph{System Pipeline:}
\begin{center}
\begin{tabular}{c}
Data $\rightarrow$ Feature Engineering $\rightarrow$ HMM \& LSTM $\rightarrow$ BMA (Ensemble) $\rightarrow$ Signals $\rightarrow$ Risk Engine $\rightarrow$ Backtest $\rightarrow$ Evaluation
\end{tabular}
\end{center}
